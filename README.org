* Transformers.jl
Julia implementation of NLP models, that based on google [[https://arxiv.org/abs/1706.03762][transformer]], with [[https://github.com/FluxML/Flux.jl][Flux.jl]].

* implemented model
+ [[https://arxiv.org/abs/1706.03762][Attention is all you need]]
+ [[https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf][Improving Language Understanding by Generative Pre-Training]]

* Roadmap
+ optimize performance
  *notice*: currently GPU version is way slower than CPU version due to performance issue of permutedim on CuArray
+ text related util functions
+ better dataset API
+ more datasets
+ openai gpt model
+ google bert model
